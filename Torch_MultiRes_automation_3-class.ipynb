{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "from ipyexperiments import *\n",
    "from torchsampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import gc\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,roc_auc_score,confusion_matrix\n",
    "import scikitplot as skplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_from_csv(csv_path):\n",
    "#     df=pd.read_csv(csv_path)\n",
    "#     val_index=df[df['Split']=='Val'].index().values()\n",
    "#     test_index="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#     try:\\n#         df.append(recall,precision,sensitivity,specificity) \\n    \\n            \\n#     except NameError as e:\\n#         df=pd.DataFrame({'recall':recall, 'precision':precision, \\n#                         'Sensitivity':sensitivity,'Specificity':specificity})\\n#     df.to_csv(f'{time.time()}-metrics-{image_size}.csv')\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def csvlogger(cnf_matrix,precision,recall):\n",
    "    tp=np.diag(cnf_matrix).astype('float')\n",
    "    fp=cnf_matrix.sum(axis=0)-np.diag(cnf_matrix).astype('float')\n",
    "    fn=cnf_matrix.sum(axis=1)-np.diag(cnf_matrix).astype('float')\n",
    "    tn=cnf_matrix.sum()-(fp+fn+tp).astype('float')\n",
    "    sensitivity=tp/(tp+fn)\n",
    "    specificity=tn/(tn+fp)\n",
    "    print(f'''recall:{recall}, precision:{precision}, \n",
    "                         Sensitivity:{sensitivity},Specificity:{specificity})''')\n",
    "'''\n",
    "#     try:\n",
    "#         df.append(recall,precision,sensitivity,specificity) \n",
    "    \n",
    "            \n",
    "#     except NameError as e:\n",
    "#         df=pd.DataFrame({'recall':recall, 'precision':precision, \n",
    "#                         'Sensitivity':sensitivity,'Specificity':specificity})\n",
    "#     df.to_csv(f'{time.time()}-metrics-{image_size}.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-50d0a4bd6c91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mIPyExperimentsPytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexp1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mb_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/ipyexperiments/ipyexperiments.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'IPyExperimentsPytorch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting IPyExperimentsPytorch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/ipyexperiments/ipyexperiments.py\u001b[0m in \u001b[0;36mbackend_init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# force pytorch to pre-load cuDNN and its kernels to claim unreclaimable memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;31m# check that all is ready to go, and we get the RAM info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function CellLogger.post_run_cell at 0x7f5d53a99d08> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/ipyexperiments/cell_logger.py\u001b[0m in \u001b[0;36mpost_run_cell\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_mem_used_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_ram_used\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;31m# delta_used is the difference between current used mem and used mem at the start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/ipyexperiments/ipyexperiments.py\u001b[0m in \u001b[0;36mgpu_ram_used\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mgpu_ram_used\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_ram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgpu_ram_avail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_ram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0;31m# use cached handle and clear no cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/ipyexperiments/ipyexperiments.py\u001b[0m in \u001b[0;36mgpu_ram\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgpu_ram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;34m\"\"\" for the currently selected GPU device return: total, free and used RAM in bytes \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_clear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# clear cache to report the correct data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpynvml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvmlDeviceGetHandleByIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu_current_device_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0minfo\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpynvml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvmlDeviceGetMemoryInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/ipyexperiments/ipyexperiments.py\u001b[0m in \u001b[0;36mgpu_clear_cache\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;31m#    super().start()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mgpu_clear_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    459\u001b[0m     \"\"\"\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_emptyCache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "image_size=64\n",
    "num_epoch=20\n",
    "input_path='/media/advenio/New Volume/New_data/final_data_subset/'\n",
    "\n",
    "for i in range(3):\n",
    "    with IPyExperimentsPytorch() as exp1:\n",
    "        b_sizes=[256,64,5]\n",
    "        weights=[64,128]\n",
    "        \n",
    "        model = models.resnet34(pretrained=False).cuda()\n",
    "        model.fc = nn.Sequential(\n",
    "                       nn.Linear(512, 256),\n",
    "                       nn.ReLU(inplace=True),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 3)).cuda()\n",
    "        \n",
    "        if i>0:\n",
    "            model.load_state_dict(torch.load(f'./models/torch_cascade_Normal_Abnormal_{weights[i-1]}.h5'))\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        image_size*=(2**i)\n",
    "        \n",
    "        batchsize=b_sizes[i]\n",
    "        \n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "        data_transforms = {\n",
    "            'train':\n",
    "            transforms.Compose([\n",
    "                transforms.Resize((image_size,image_size)),\n",
    "                transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ]),\n",
    "            'validation':\n",
    "            transforms.Compose([\n",
    "                transforms.Resize((image_size,image_size)),\n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "            ]),\n",
    "        }\n",
    "\n",
    "        image_datasets = {\n",
    "            'train': \n",
    "            datasets.ImageFolder(input_path + 'train', data_transforms['train']),\n",
    "            'validation': \n",
    "            datasets.ImageFolder(input_path + 'val', data_transforms['validation'])\n",
    "        }\n",
    "\n",
    "        dataloaders = {\n",
    "            'train':\n",
    "            torch.utils.data.DataLoader(image_datasets['train'],\n",
    "                                        batch_size=batchsize,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=0,),\n",
    "                                       #sampler=ImbalancedDatasetSampler(image_datasets['train'])),  \n",
    "            'validation':\n",
    "            torch.utils.data.DataLoader(image_datasets['validation'],\n",
    "                                        batch_size=batchsize,\n",
    "                                        shuffle=True,\n",
    "                                        num_workers=0,)\n",
    "                                       #sampler=ImbalancedDatasetSampler(image_datasets['validation']))  \n",
    "        }\n",
    "        #weights=torch.tensor([(5492/19251),(13759/19251)])\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.fc.parameters())\n",
    "\n",
    "        def train_model(model, criterion, optimizer, num_epochs=3):\n",
    "            accuracy=[]\n",
    "            predictions=[]\n",
    "            targets=[]\n",
    "            for epoch in range(num_epochs):\n",
    "                epoch_preds=[]\n",
    "                epoch_labels=[]\n",
    "                print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "                print('-' * 10)\n",
    "\n",
    "                for phase in ['train', 'validation']:\n",
    "                    since=time.time()\n",
    "                    if phase == 'train':\n",
    "                        model.train()\n",
    "                    else:\n",
    "                        model.eval()\n",
    "\n",
    "                    running_loss = 0.0\n",
    "                    running_corrects = 0\n",
    "\n",
    "                    for inputs, labels in dataloaders[phase]:\n",
    "                        inputs = inputs.cuda()\n",
    "                        labels = labels.cuda()\n",
    "\n",
    "                        outputs = model(inputs)\n",
    "                        outputs=outputs.cuda()\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                        if phase == 'train':\n",
    "                            optimizer.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        running_loss += loss.item() * inputs.size(0)\n",
    "                        running_corrects += torch.sum(preds == labels.data)\n",
    "                        preds=list(map(int,preds))\n",
    "                        labels=list(map(int,labels.data.cpu()))\n",
    "                        epoch_preds.extend(preds)\n",
    "                        epoch_labels.extend(labels)\n",
    "                        predictions.extend(preds)\n",
    "                        targets.extend(labels)\n",
    "                    time_taken=(time.time()-since)/float(60)\n",
    "                    epoch_loss = running_loss / len(image_datasets[phase])\n",
    "                    epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "                    precision=precision_score(epoch_labels,epoch_preds,average='macro')\n",
    "                    recall=recall_score(epoch_labels,epoch_preds,average='macro')\n",
    "                    #roc_score=roc_auc_score(epoch_labels,epoch_preds,average='micro')\n",
    "                    print(f'Precision::{precision} Recall::{recall} ')\n",
    "\n",
    "                    print('{} loss: {:.4f}, acc: {:.4f}, time: {}'.format(phase,\n",
    "                                                                epoch_loss,\n",
    "                                                                epoch_acc,time_taken))\n",
    "            #if len(set(labels))==2:\n",
    "            \n",
    "            cnf_matrix=confusion_matrix(targets, predictions)\n",
    "            skplt.metrics.plot_confusion_matrix(targets, predictions, normalize=False)\n",
    "            plt.show()\n",
    "            csvlogger(cnf_matrix,precision,recall)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            #return model\n",
    "            #torch.save(model.state_dict(),f'./models/torch_cascade_Normal_Abnormal_{image_size}.h5')\n",
    "            return 0\n",
    "\n",
    "\n",
    "        model_trained = train_model(model, criterion, optimizer, num_epochs=num_epoch)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INFERNECE FOR Multi-class MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference Script\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "from ipyexperiments import *\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import gc\n",
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from torchvision import models \n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = models.resnet34(pretrained=False).cuda()\n",
    "model1.fc = nn.Sequential(\n",
    "               nn.Linear(512, 256),\n",
    "               nn.ReLU(inplace=True),\n",
    "    nn.Linear(256,128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2))\n",
    "model1.load_state_dict(torch.load('/media/advenio/New Volume/models/torch_cascade_Normal_Abnormal_128.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = models.resnet34(pretrained=False).cuda()\n",
    "model1.fc = nn.Sequential(\n",
    "               nn.Linear(512, 256),\n",
    "               nn.ReLU(inplace=True),\n",
    "    nn.Linear(256,128),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(128, 2)).cuda()\n",
    "model2 = models.resnet50(pretrained=False).cuda()\n",
    "model2.fc = nn.Sequential(\n",
    "               nn.Linear(2048, 512),\n",
    "               nn.ReLU(inplace=True),\n",
    "            nn.Linear(512,256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 2)).cuda()\n",
    "model1.load_state_dict(torch.load('/media/advenio/New Volume//models/torch_cascade_Normal_Abnormal_128.h5'))\n",
    "model2.load_state_dict(torch.load('/media/advenio/New Volume//models/Torch_cascade_Subtle-Normal_weights_128.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(path):\n",
    "    img=Image.open(path)\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    image_size=128\n",
    "    test_transforms=transforms.Compose([\n",
    "                    transforms.Resize((image_size,image_size)),\n",
    "                    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize])\n",
    "    img=test_transforms(img).cuda()\n",
    "    img=torch.unsqueeze(img,0)\n",
    "    #print(type(img))\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "    result=model1(img)\n",
    "    prediction1=F.softmax(result).cpu().detach().numpy()\n",
    "    \n",
    "    if np.argmax(prediction1[0])==1:\n",
    "        print('Abnormal')\n",
    "    elif np.argmax(prediction1[0])==0:\n",
    "        pred=model2(img)\n",
    "        prediction2=F.softmax(pred).cpu().detach().numpy()\n",
    "        if np.argmax(prediction2[0])==1:\n",
    "            print('Subtle Normal')\n",
    "        elif np.argmax(prediction2[0])==0 :\n",
    "            print('Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/advenio/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abnormal\n",
      "Abnormal\n",
      "Abnormal\n",
      "Normal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/advenio/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abnormal\n",
      "Abnormal\n",
      "Abnormal\n",
      "Abnormal\n",
      "Normal\n",
      "Normal\n",
      "Abnormal\n",
      "Abnormal\n",
      "Abnormal\n",
      "Abnormal\n",
      "Abnormal\n",
      "Abnormal\n",
      "Normal\n",
      "Normal\n",
      "Abnormal\n",
      "Abnormal\n",
      "Normal\n"
     ]
    }
   ],
   "source": [
    "path='/media/advenio/UBUNTU 18_0/testing/'\n",
    "for i in os.listdir(path):\n",
    "    image_path=path+'/'+i\n",
    "    inference(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtle(path):\n",
    "    img=Image.open(path)\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    image_size=128\n",
    "    test_transforms=transforms.Compose([\n",
    "                    transforms.Resize((image_size,image_size)),\n",
    "                    transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize])\n",
    "    img=test_transforms(img).cuda()\n",
    "    img=torch.unsqueeze(img,0)\n",
    "    pred=model2(img)\n",
    "    prediction2=F.softmax(pred).cpu().detach().numpy()\n",
    "    if np.argmax(prediction2[0])==1:\n",
    "        print('Subtle Normal')\n",
    "    elif np.argmax(prediction2[0])==0 :\n",
    "        print('Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/advenio/anaconda3/envs/fastai/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n",
      "Normal\n"
     ]
    }
   ],
   "source": [
    "path='/media/advenio/UBUNTU 18_0/testing/'\n",
    "for i in os.listdir(path):\n",
    "    image_path=path+'/'+i\n",
    "    subtle(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=Image.open('')\n",
    "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                  std=[0.229, 0.224, 0.225])\n",
    "# image_size=128\n",
    "# test_transforms=transforms.Compose([\n",
    "#                 transforms.Resize((image_size,image_size)),\n",
    "#                 transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)),\n",
    "#                 transforms.RandomHorizontalFlip(),\n",
    "#                 transforms.ToTensor(),\n",
    "#                 normalize])\n",
    "# img=test_transforms(img).cuda()\n",
    "# img=torch.unsqueeze(img,0)\n",
    "# result=model1(img)\n",
    "# prediction1=F.softmax(result).cpu().detach().numpy()\n",
    "# prediction1\n",
    "# np.argmax()\n",
    "# if np.argmax(prediction1[0])==1:\n",
    "#     print('Abnormal')\n",
    "# elif np.argmax(k[0])==0:\n",
    "#     pred=model2(img)\n",
    "#     predicition2=F.softmax(result).cpu().detach().numpy()\n",
    "#     if np.argmax(prediction2[0])==1:\n",
    "#         print('Subtle Normal')\n",
    "#     elif np.argmax(prediction2[0])==0 :\n",
    "#         print('Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
